{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n\nimport lightgbm as lgb\nimport catboost as ctb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve\nfrom sklearn.metrics import classification_report\n\nimport graphviz\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas_profiling\ntrain.profile_report()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([train, test], sort = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.hist(train.loc[train['Survived'] ==0, 'Age'].dropna(), bins=30, alpha = 0.5, label='0')\nplt.hist(train.loc[train['Survived'] ==1, 'Age'].dropna(), bins=30, alpha = 0.5, label='1')\nplt.xlabel('Age')\nplt.ylabel('count')\nplt.legend(title='Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='SibSp', hue='Survived', data = train)\nplt.legend(loc='upper right', title='Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='Parch', hue='Survived', data = train)\nplt.legend(loc='upper right', title='Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The higher the fare, the higher the survival rate.\nplt.hist(train.loc[train['Survived'] ==0, 'Fare'].dropna(), range=(0, 250), bins=30, alpha = 0.5, label='0')\nplt.hist(train.loc[train['Survived'] ==1, 'Fare'].dropna(), range=(0, 250), bins=30, alpha = 0.5, label='1')\nplt.xlabel('Fare')\nplt.ylabel('count')\nplt.legend(title='Survived')\nplt.xlim(-5, 250)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='Pclass', hue='Survived', data = train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='Sex', hue='Survived', data = train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='Embarked', hue='Survived', data = train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Embarked\ndata['Embarked'].value_counts() #data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \n#  3   Name         200000 non-null  object                          -- label_cols\n#  4   Sex          200000 non-null  object                          -- label_cols\n#  5   Age          193416 non-null  float64    -- missing value \n#  8   Ticket       190754 non-null  object     -- missing value     -- label_cols\n#  9   Fare         199732 non-null  float64    -- missing value \n#  10  Cabin        64268 non-null   object     -- missing value     -- onehot_cols\n#  11  Embarked     199500 non-null  object     -- missing value     -- onehot_cols\n\n# https://www.kaggle.com/hiro5299834/tps-apr-2021-pseudo-labeling-voting-ensemble\n\n\n# Name, take only surnames\ndata['Name'] = data['Name'].map(lambda x: x.split(',')[0])\n\nage_avg = data['Age'].mean()\nage_std = data['Age'].std()\ndata['Age'].fillna(np.random.randint(age_avg - age_std, age_avg + age_std), inplace=True)\n\n\n# Ticket, fillna with 'X', split string and take first split \ndata['Ticket'] = data['Ticket'].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n\ndata['Fare'].fillna(np.mean(data['Fare']), inplace=True)\n\n# Cabin, fillna with 'X' and take first letter\ndata['Cabin'] = data['Cabin'].fillna('X').map(lambda x: x[0].strip())\n\n# Embarked, fillna with 'X' value\ndata['Embarked'] = data['Embarked'].fillna('X')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Name.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_cols = ['Name', 'Ticket', 'Sex']\nonehot_cols = ['Cabin', 'Embarked']\nnumerical_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_encoder(c):\n    le = LabelEncoder()\n    return le.fit_transform(c)\n\nscaler = StandardScaler()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"onehot_encoded_df = pd.get_dummies(data[onehot_cols])\nonehot_encoded_df.reset_index(inplace=True, drop=True)\nonehot_encoded_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoded_df = data[label_cols].apply(label_encoder)\nlabel_encoded_df.reset_index(inplace=True, drop=True)\nlabel_encoded_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_df = pd.DataFrame(scaler.fit_transform(data[numerical_cols]), columns=numerical_cols)\nnumerical_df.reset_index(inplace=True, drop=True)\nnumerical_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_df = data['Survived']\ntarget_df.reset_index(inplace=True, drop=True)\ntarget_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([numerical_df, label_encoded_df, onehot_encoded_df, target_df], axis=1) \ndata = data.reset_index(drop=True)\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = data[:len(train)]\ntest = data[len(train):]\ny_train = train['Survived']\nX_train = train.drop('Survived', axis=1)\nx_test = test.drop('Survived', axis=1)\ny_test= test['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(16,12))\nsns.heatmap(data.corr(), annot=True, cmap=\"RdYlGn\")\nfig.tight_layout()\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression Model","metadata":{}},{"cell_type":"code","source":"clf = LogisticRegression(penalty='l2', solver = 'sag', random_state=0) # 답을 찾는 방법.. 확률적 경사하강법 \nclf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = clf.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_test, predictions)  # 이걸로 안돼는뎅 ㅎㅎ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probabilities = clf.predict_proba(x_test)[:, 1]\nprobabilities.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(y_test, probabilities)\n\nfig, ax = plt.subplots(figsize=(12, 6))\n\nax.plot(fpr, tpr)\nax.set_xlabel(\"False Positive Rate (1 - Specificity)\")\nax.set_ylabel(\"True Positive Rate (Sensitivity, Recall)\")\nax.set_title(\"ROC Plot of Titanic Data\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr, tpr, thresholds ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree Model","metadata":{}},{"cell_type":"code","source":"N_ESTIMATORS = 1000\nN_SPLITS = 10\nSEED = 2021\nEARLY_STOPPING_ROUNDS = 100\nVERBOSE = 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/hiro5299834/tps-apr-2021-pseudo-labeling-voting-ensemble \n\n# Tuning the DecisionTreeClassifier by the GridSearchCV\nparameters = {\n    'max_depth': np.arange(2, 5, dtype=int),\n    'min_samples_leaf':  np.arange(2, 5, dtype=int)\n}\n\nclassifier = DecisionTreeClassifier(random_state=2021)\n\nmodel = GridSearchCV(\n    estimator=classifier,\n    param_grid=parameters,\n    scoring='accuracy',\n    cv=10,\n    n_jobs=-1)\nmodel.fit(X_train, y_train)\n\nbest_parameters = model.best_params_\nprint(best_parameters)\n\n# {'max_depth': 4, 'min_samples_leaf': 2}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 2021\ndtm_oof = np.zeros(train.shape[0])\ndtm_preds = np.zeros(test.shape[0])\nfeature_importances = pd.DataFrame()\n\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(data,data['Survived'])):\n    print(f\"===== FOLD {fold} =====\")\n    oof_idx = np.array([idx for idx in valid_idx if idx < train.shape[0]])\n    preds_idx = np.array([idx for idx in valid_idx if idx >= train.shape[0]])\n\n    X_train, y_train = data.iloc[train_idx].drop('Survived', axis=1), data.iloc[train_idx]['Survived']\n    X_valid, y_valid = data.iloc[oof_idx].drop('Survived', axis=1), data.iloc[oof_idx]['Survived']\n    X_test = data.iloc[preds_idx].drop('Survived', axis=1)\n    \n    model = DecisionTreeClassifier(\n        max_depth=best_parameters['max_depth'],\n        min_samples_leaf=best_parameters['min_samples_leaf'],\n        random_state=SEED\n    )\n    model.fit(X_train, y_train)\n    \n    dtm_oof[oof_idx] = model.predict(X_valid)\n    dtm_preds[preds_idx-train.shape[0]] = model.predict(x_test)\n    \n    acc_score = accuracy_score(y_valid, np.where(dtm_oof[oof_idx]>0.5, 1, 0))\n    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")\n    \nacc_score = accuracy_score(data[:train.shape[0]]['Survived'], np.where(dtm_oof>0.5, 1, 0))\nprint(f\"===== ACCURACY SCORE {acc_score:.6f} =====\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot tree\ndot_data = export_graphviz(\n    model,\n    out_file=None,\n    feature_names=X_train.columns,\n    class_names=['0', '1'],\n    filled=True,\n    rounded=False,\n    special_characters=True,\n    precision=3\n)\ngraph = graphviz.Source(dot_data)\ngraph ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LGB Boost\nRandom Forest\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}