{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as ctb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\n",
    "test = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\n",
    "sample_submission = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "train.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, test], sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.hist(train.loc[train['Survived'] ==0, 'Age'].dropna(), bins=30, alpha = 0.5, label='0')\n",
    "plt.hist(train.loc[train['Survived'] ==1, 'Age'].dropna(), bins=30, alpha = 0.5, label='1')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('count')\n",
    "plt.legend(title='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='SibSp', hue='Survived', data = train)\n",
    "plt.legend(loc='upper right', title='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Parch', hue='Survived', data = train)\n",
    "plt.legend(loc='upper right', title='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The higher the fare, the higher the survival rate.\n",
    "plt.hist(train.loc[train['Survived'] ==0, 'Fare'].dropna(), range=(0, 250), bins=30, alpha = 0.5, label='0')\n",
    "plt.hist(train.loc[train['Survived'] ==1, 'Fare'].dropna(), range=(0, 250), bins=30, alpha = 0.5, label='1')\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('count')\n",
    "plt.legend(title='Survived')\n",
    "plt.xlim(-5, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Pclass', hue='Survived', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Sex', hue='Survived', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Embarked', hue='Survived', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embarked\n",
    "data['Embarked'].value_counts() #data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#  3   Name         200000 non-null  object                          -- label_cols\n",
    "#  4   Sex          200000 non-null  object                          -- label_cols\n",
    "#  5   Age          193416 non-null  float64    -- missing value \n",
    "#  8   Ticket       190754 non-null  object     -- missing value     -- label_cols\n",
    "#  9   Fare         199732 non-null  float64    -- missing value \n",
    "#  10  Cabin        64268 non-null   object     -- missing value     -- onehot_cols\n",
    "#  11  Embarked     199500 non-null  object     -- missing value     -- onehot_cols\n",
    "\n",
    "# https://www.kaggle.com/hiro5299834/tps-apr-2021-pseudo-labeling-voting-ensemble\n",
    "\n",
    "\n",
    "# Name, take only surnames\n",
    "data['Name'] = data['Name'].map(lambda x: x.split(',')[0])\n",
    "\n",
    "age_avg = data['Age'].mean()\n",
    "age_std = data['Age'].std()\n",
    "data['Age'].fillna(np.random.randint(age_avg - age_std, age_avg + age_std), inplace=True)\n",
    "\n",
    "\n",
    "# Ticket, fillna with 'X', split string and take first split \n",
    "data['Ticket'] = data['Ticket'].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n",
    "\n",
    "data['Fare'].fillna(np.mean(data['Fare']), inplace=True)\n",
    "\n",
    "# Cabin, fillna with 'X' and take first letter\n",
    "data['Cabin'] = data['Cabin'].fillna('X').map(lambda x: x[0].strip())\n",
    "\n",
    "# Embarked, fillna with 'X' value\n",
    "data['Embarked'] = data['Embarked'].fillna('X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['Name', 'Ticket', 'Sex']\n",
    "onehot_cols = ['Cabin', 'Embarked']\n",
    "numerical_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(c):\n",
    "    le = LabelEncoder()\n",
    "    return le.fit_transform(c)\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoded_df = pd.get_dummies(data[onehot_cols])\n",
    "onehot_encoded_df.reset_index(inplace=True, drop=True)\n",
    "onehot_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoded_df = data[label_cols].apply(label_encoder)\n",
    "label_encoded_df.reset_index(inplace=True, drop=True)\n",
    "label_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df = pd.DataFrame(scaler.fit_transform(data[numerical_cols]), columns=numerical_cols)\n",
    "numerical_df.reset_index(inplace=True, drop=True)\n",
    "numerical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = data['Survived']\n",
    "target_df.reset_index(inplace=True, drop=True)\n",
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([numerical_df, label_encoded_df, onehot_encoded_df, target_df], axis=1) \n",
    "data = data.reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:len(train)]\n",
    "test = data[len(train):]\n",
    "y_train = train['Survived']\n",
    "X_train = train.drop('Survived', axis=1)\n",
    "x_test = test.drop('Survived', axis=1)\n",
    "y_test= test['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(16,12))\n",
    "sns.heatmap(data.corr(), annot=True, cmap=\"RdYlGn\")\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l2', solver = 'sag', random_state=0) # 답을 찾는 방법.. 확률적 경사하강법 \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)  # 이걸로 안돼는뎅 ㅎㅎ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = clf.predict_proba(x_test)[:, 1]\n",
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, probabilities)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(fpr, tpr)\n",
    "ax.set_xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "ax.set_ylabel(\"True Positive Rate (Sensitivity, Recall)\")\n",
    "ax.set_title(\"ROC Plot of Titanic Data\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ESTIMATORS = 1000\n",
    "N_SPLITS = 10\n",
    "SEED = 2021\n",
    "EARLY_STOPPING_ROUNDS = 100\n",
    "VERBOSE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/hiro5299834/tps-apr-2021-pseudo-labeling-voting-ensemble \n",
    "\n",
    "# Tuning the DecisionTreeClassifier by the GridSearchCV\n",
    "parameters = {\n",
    "    'max_depth': np.arange(2, 5, dtype=int),\n",
    "    'min_samples_leaf':  np.arange(2, 5, dtype=int)\n",
    "}\n",
    "\n",
    "classifier = DecisionTreeClassifier(random_state=2021)\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=classifier,\n",
    "    param_grid=parameters,\n",
    "    scoring='accuracy',\n",
    "    cv=10,\n",
    "    n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "best_parameters = model.best_params_\n",
    "print(best_parameters)\n",
    "\n",
    "# {'max_depth': 4, 'min_samples_leaf': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "dtm_oof = np.zeros(train.shape[0])\n",
    "dtm_preds = np.zeros(test.shape[0])\n",
    "feature_importances = pd.DataFrame()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(data,data['Survived'])):\n",
    "    print(f\"===== FOLD {fold} =====\")\n",
    "    oof_idx = np.array([idx for idx in valid_idx if idx < train.shape[0]])\n",
    "    preds_idx = np.array([idx for idx in valid_idx if idx >= train.shape[0]])\n",
    "\n",
    "    X_train, y_train = data.iloc[train_idx].drop('Survived', axis=1), data.iloc[train_idx]['Survived']\n",
    "    X_valid, y_valid = data.iloc[oof_idx].drop('Survived', axis=1), data.iloc[oof_idx]['Survived']\n",
    "    X_test = data.iloc[preds_idx].drop('Survived', axis=1)\n",
    "    \n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=best_parameters['max_depth'],\n",
    "        min_samples_leaf=best_parameters['min_samples_leaf'],\n",
    "        random_state=SEED\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    dtm_oof[oof_idx] = model.predict(X_valid)\n",
    "    dtm_preds[preds_idx-train.shape[0]] = model.predict(x_test)\n",
    "    \n",
    "    acc_score = accuracy_score(y_valid, np.where(dtm_oof[oof_idx]>0.5, 1, 0))\n",
    "    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")\n",
    "    \n",
    "acc_score = accuracy_score(data[:train.shape[0]]['Survived'], np.where(dtm_oof>0.5, 1, 0))\n",
    "print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot tree\n",
    "dot_data = export_graphviz(\n",
    "    model,\n",
    "    out_file=None,\n",
    "    feature_names=X_train.columns,\n",
    "    class_names=['0', '1'],\n",
    "    filled=True,\n",
    "    rounded=False,\n",
    "    special_characters=True,\n",
    "    precision=3\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB Boost\n",
    "Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
